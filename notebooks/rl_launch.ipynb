{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition module dir to path\n",
    "module_dir = os.path.split( os.getcwd() )[:-1][0]\n",
    "sys.path.append(module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs.wh_env import WarehouseEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.getcwd()\n",
    "data_dir = '/Users/albelyakov/Data/rl_warehouse'\n",
    "models_dir = os.path.join(module_dir, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs import wh_map as wm\n",
    "from src.envs import wh_objects as wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import readline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from collections import Counter, deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.core import Processor\n",
    "from rl.policy import BoltzmannQPolicy, LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.callbacks import ModelIntervalCheckpoint, FileLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 11:43:29.604804 4395738560 deprecation_wrapper.py:119] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0722 11:43:29.605510 4395738560 deprecation_wrapper.py:119] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0722 11:43:29.606575 4395738560 deprecation_wrapper.py:119] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0722 11:43:29.788007 4395738560 deprecation_wrapper.py:119] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, n_actions):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.15))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_actions, activation='linear'))\n",
    "    model.compile(Adam(lr=1e-3), 'mae', batch_size=256)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProcessor(Processor):\n",
    "    '''\n",
    "    acts as a coupling mechanism between the agent and the environment\n",
    "    '''\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        '''\n",
    "        Given a state batch, I want to remove the second dimension, because it's\n",
    "        useless and prevents me from feeding the tensor into my CNN\n",
    "        '''\n",
    "        return np.squeeze(batch, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_callbacks(env_name):\n",
    "    checkpoint_weights_filename = 'callbacks/'+'dqn_' + env_name + '_weights_{step}.h5f'\n",
    "    log_filename = 'dqn_{}_log.json'.format(env_name)\n",
    "    callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=50000)]\n",
    "    callbacks += [FileLogger(log_filename, interval=100)]\n",
    "#     callbacks += [ReduceLROnPlateau(\n",
    "#         monitor='val_acc', patience=5, verbose=1, factor=0.5, min_lr=1e-4\n",
    "#     )]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WarehouseEnv(\n",
    "    map_sketch=wm.wh_vis_map, \n",
    "    catalog=None, \n",
    "    num_turns=2000, \n",
    "    max_order_line=None,\n",
    "    agent_max_load=200, \n",
    "    agent_max_volume=1000,\n",
    "    agent_start_pos=(18, 9),\n",
    "    shelf_max_load=200, \n",
    "    shelf_max_volume=100,\n",
    "    frequency=0.05, \n",
    "    simplified_state=False,\n",
    "    only_one_product= True, \n",
    "    win_size=(300, 200), \n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 11:58:27.372644 4395738560 deprecation_wrapper.py:119] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0722 11:58:27.431739 4395738560 deprecation_wrapper.py:119] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0722 11:58:27.439254 4395738560 deprecation.py:506] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0722 11:58:27.532946 4395738560 deprecation_wrapper.py:119] From /anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape=(23,20,1), n_actions=env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('callbacks/dqn_rl-run_weights_350000.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CustomProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=500000, window_length=4)\n",
    "# policy = BoltzmannQPolicy()\n",
    "policy = LinearAnnealedPolicy(\n",
    "    EpsGreedyQPolicy(), \n",
    "    attr='eps', \n",
    "    value_max=.8, \n",
    "    value_min=.1, \n",
    "    value_test=.05, \n",
    "    nb_steps=500000\n",
    ")\n",
    "dqn = DQNAgent(\n",
    "    model=model, \n",
    "    nb_actions=env.action_space.n, \n",
    "    memory=memory, \n",
    "    nb_steps_warmup=512,\n",
    "    target_model_update=1e-2, \n",
    "    policy=policy, \n",
    "    processor=processor, \n",
    "    batch_size=512\n",
    ")\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = build_callbacks('rl-run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 500000 steps ...\n",
      "done, took 218.823 seconds\n",
      "CPU times: user 9min 49s, sys: 1min 15s, total: 11min 4s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = dqn.fit(env, nb_steps=500000, visualize=True, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
