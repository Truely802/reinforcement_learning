{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition module dir to path\n",
    "module_dir = os.path.split( os.getcwd() )[:-1][0]\n",
    "sys.path.append(module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs.wh_env import WarehouseEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.getcwd()\n",
    "data_dir = '/Users/albelyakov/Data/rl_warehouse'\n",
    "models_dir = os.path.join(module_dir, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs import wh_map as wm\n",
    "from src.envs import wh_objects as wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import readline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from collections import Counter, deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.core import Processor\n",
    "from rl.policy import BoltzmannQPolicy, LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.callbacks import ModelIntervalCheckpoint, FileLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, n_actions):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.15))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_actions, activation='linear'))\n",
    "    model.compile(Adam(lr=1e-3), 'mae', batch_size=256)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProcessor(Processor):\n",
    "    '''\n",
    "    acts as a coupling mechanism between the agent and the environment\n",
    "    '''\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        '''\n",
    "        Given a state batch, I want to remove the second dimension, because it's\n",
    "        useless and prevents me from feeding the tensor into my CNN\n",
    "        '''\n",
    "        return np.squeeze(batch, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_callbacks(env_name):\n",
    "    checkpoint_weights_filename = 'callbacks/'+'dqn_' + env_name + '_weights_{step}.h5f'\n",
    "    log_filename = 'dqn_{}_log.json'.format(env_name)\n",
    "    callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=50000)]\n",
    "    callbacks += [FileLogger(log_filename, interval=100)]\n",
    "#     callbacks += [ReduceLROnPlateau(\n",
    "#         monitor='val_acc', patience=5, verbose=1, factor=0.5, min_lr=1e-4\n",
    "#     )]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WarehouseEnv(\n",
    "    map_sketch=wm.wh_vis_map, \n",
    "    catalog=None, \n",
    "    num_turns=2000, \n",
    "    max_order_line=None,\n",
    "    agent_max_load=200, \n",
    "    agent_max_volume=1000,\n",
    "    agent_start_pos=(18, 9),\n",
    "    shelf_max_load=200, \n",
    "    shelf_max_volume=100,\n",
    "    frequency=0.05, \n",
    "    simplified_state=False,\n",
    "    only_one_product= True, \n",
    "    win_size=(300, 300), \n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(23,20,1), n_actions=env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('dqn_rl-test_weights_350000.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CustomProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "# policy = BoltzmannQPolicy()\n",
    "policy = LinearAnnealedPolicy(\n",
    "    EpsGreedyQPolicy(), \n",
    "    attr='eps', \n",
    "    value_max=.8, \n",
    "    value_min=.1, \n",
    "    value_test=.05, \n",
    "    nb_steps=500000\n",
    ")\n",
    "dqn = DQNAgent(\n",
    "    model=model, \n",
    "    nb_actions=env.action_space.n, \n",
    "    memory=memory, \n",
    "    nb_steps_warmup=256,\n",
    "    target_model_update=1e-2, \n",
    "    policy=policy, \n",
    "    processor=processor, \n",
    "    batch_size=512\n",
    ")\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = build_callbacks('rl-run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 500000 steps ...\n",
      "   2000/500000: episode: 1, duration: 68.827s, episode steps: 2000, steps per second: 29, episode reward: -8246.000, mean reward: -4.123 [-10.000, 0.000], mean action: 3.154 [0.000, 6.000], mean observation: 56.837 [0.000, 255.000], loss: 69.740472, mean_absolute_error: 60.195942, mean_q: 76.270905, mean_eps: 0.798421\n",
      "   4000/500000: episode: 2, duration: 76.783s, episode steps: 2000, steps per second: 26, episode reward: -8876.000, mean reward: -4.438 [-10.000, 0.000], mean action: 2.884 [0.000, 6.000], mean observation: 54.902 [0.000, 255.000], loss: 83.409856, mean_absolute_error: 66.368887, mean_q: 84.891629, mean_eps: 0.795801\n",
      "   6000/500000: episode: 3, duration: 76.668s, episode steps: 2000, steps per second: 26, episode reward: -8653.000, mean reward: -4.327 [-10.000, 0.000], mean action: 2.884 [0.000, 6.000], mean observation: 54.902 [0.000, 255.000], loss: 75.026836, mean_absolute_error: 81.907022, mean_q: 102.718053, mean_eps: 0.793001\n",
      "   8000/500000: episode: 4, duration: 77.206s, episode steps: 2000, steps per second: 26, episode reward: -8254.000, mean reward: -4.127 [-10.000, 0.000], mean action: 3.061 [0.000, 6.000], mean observation: 56.837 [0.000, 255.000], loss: 70.017188, mean_absolute_error: 74.613517, mean_q: 93.433780, mean_eps: 0.790201\n",
      "  10000/500000: episode: 5, duration: 76.820s, episode steps: 2000, steps per second: 26, episode reward: -8392.000, mean reward: -4.196 [-10.000, 0.000], mean action: 2.927 [0.000, 6.000], mean observation: 54.902 [0.000, 255.000], loss: 57.976012, mean_absolute_error: 59.249245, mean_q: 75.336384, mean_eps: 0.787401\n",
      "  12000/500000: episode: 6, duration: 76.859s, episode steps: 2000, steps per second: 26, episode reward: -8572.000, mean reward: -4.286 [-10.000, 0.000], mean action: 2.793 [0.000, 6.000], mean observation: 55.289 [0.000, 255.000], loss: 57.719663, mean_absolute_error: 45.489642, mean_q: 58.623812, mean_eps: 0.784601\n",
      "  14000/500000: episode: 7, duration: 77.010s, episode steps: 2000, steps per second: 26, episode reward: -8382.000, mean reward: -4.191 [-10.000, 0.000], mean action: 3.100 [0.000, 6.000], mean observation: 56.450 [0.000, 255.000], loss: 51.700019, mean_absolute_error: 37.495539, mean_q: 47.962341, mean_eps: 0.781801\n",
      "  16000/500000: episode: 8, duration: 77.164s, episode steps: 2000, steps per second: 26, episode reward: -8387.000, mean reward: -4.194 [-10.000, 50.000], mean action: 2.762 [0.000, 6.000], mean observation: 56.692 [0.000, 255.000], loss: 54.643309, mean_absolute_error: 30.235372, mean_q: 37.447223, mean_eps: 0.779001\n",
      "  18000/500000: episode: 9, duration: 77.196s, episode steps: 2000, steps per second: 26, episode reward: -9730.000, mean reward: -4.865 [-1000.000, 50.000], mean action: 3.022 [0.000, 6.000], mean observation: 55.293 [0.000, 255.000], loss: 55.234114, mean_absolute_error: 24.729303, mean_q: 25.897032, mean_eps: 0.776201\n",
      "  20000/500000: episode: 10, duration: 77.778s, episode steps: 2000, steps per second: 26, episode reward: -7446.000, mean reward: -3.723 [-10.000, 0.000], mean action: 3.143 [0.000, 6.000], mean observation: 54.902 [0.000, 255.000], loss: 64.376526, mean_absolute_error: 24.510522, mean_q: 17.545631, mean_eps: 0.773401\n",
      "  22000/500000: episode: 11, duration: 78.033s, episode steps: 2000, steps per second: 26, episode reward: -7565.000, mean reward: -3.783 [-10.000, 50.000], mean action: 3.158 [0.000, 6.000], mean observation: 54.897 [0.000, 255.000], loss: 54.605237, mean_absolute_error: 24.544269, mean_q: 13.659341, mean_eps: 0.770601\n",
      "  24000/500000: episode: 12, duration: 77.613s, episode steps: 2000, steps per second: 26, episode reward: -8524.000, mean reward: -4.262 [-10.000, 50.000], mean action: 3.047 [0.000, 6.000], mean observation: 56.027 [0.000, 255.000], loss: 52.651947, mean_absolute_error: 22.804556, mean_q: 14.313695, mean_eps: 0.767801\n",
      "  26000/500000: episode: 13, duration: 76.775s, episode steps: 2000, steps per second: 26, episode reward: -11751.000, mean reward: -5.875 [-1000.000, 50.000], mean action: 2.975 [0.000, 6.000], mean observation: 54.254 [0.000, 255.000], loss: 81.116728, mean_absolute_error: 25.516001, mean_q: 19.977096, mean_eps: 0.765001\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = dqn.fit(env, nb_steps=500000, visualize=True, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
