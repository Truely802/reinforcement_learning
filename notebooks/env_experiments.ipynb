{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition module dir to path\n",
    "module_dir = os.path.split( os.getcwd() )[:-1][0]\n",
    "sys.path.append(module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs.wh_env import WarehouseEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.getcwd()\n",
    "data_dir = '/Users/albelyakov/Data/rl_warehouse'\n",
    "models_dir = os.path.join(module_dir, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs import wh_map as wm\n",
    "from src.envs import wh_objects as wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import readline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_map(map_obj, agent_obj):\n",
    "#     os.system('clear')\n",
    "#     subprocess.call('reset')\n",
    "    readline.clear_history()\n",
    "    for i, row in enumerate(map_obj):\n",
    "        to_print = list()\n",
    "        for j, obj in enumerate(row):\n",
    "            if (i, j) == agent_obj.coordinates:\n",
    "                to_print.append(agent_obj.sprite)\n",
    "            else:\n",
    "                to_print.append(obj.sprite)\n",
    "        print(''.join(to_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_obj = wm.init_wh_map(wm.wh_vis_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_map(map_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = wo.Agent(\n",
    "    coordinates=(18,9)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_map(map_obj, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_loop():\n",
    "    map_obj = wm.init_wh_map(wm.wh_vis_map)\n",
    "    agent_obj = wo.Agent(\n",
    "        coordinates=(18,9)\n",
    "    )\n",
    "    availible_actions = set(['w', 'a', 's', 'd', 'q', 't', 'g', 'i', 'r'])\n",
    "    score = 0\n",
    "    render_map(map_obj, agent_obj)\n",
    "    while True:\n",
    "        while True:\n",
    "            action = input()\n",
    "            if action in availible_actions:\n",
    "                break\n",
    "        if action == 'w':\n",
    "            r = agent_obj.move(to='u',map_obj=map_obj)\n",
    "            if r == 0:\n",
    "                score -= 10\n",
    "        elif action == 'a':\n",
    "            r = agent_obj.move(to='l',map_obj=map_obj)\n",
    "            if r == 0:\n",
    "                score -= 10\n",
    "        elif action == 's':\n",
    "            r = agent_obj.move(to='d',map_obj=map_obj)\n",
    "            if r == 0:\n",
    "                score -= 10\n",
    "        elif action == 'd':\n",
    "            r = agent_obj.move(to='r',map_obj=map_obj)\n",
    "            if r == 0:\n",
    "                score -= 10\n",
    "        elif action == 'q':\n",
    "            print('Breaking simulation.')\n",
    "            break\n",
    "        elif action == 't':\n",
    "            r = agent_obj.take_product(product_name='MacBookPro', map_obj=map_obj)\n",
    "            if r == 0:\n",
    "                score -= 10\n",
    "        elif action == 'g':\n",
    "            r = agent_obj.put_product(product_name='MacBookPro', map_obj=map_obj)\n",
    "            if r == 0:\n",
    "                score -= 10\n",
    "            elif r == -1:\n",
    "                score -= 1000\n",
    "            elif r == 10:\n",
    "                score += 500\n",
    "        elif action == 'i':\n",
    "            r = agent_obj.inspect_shelf(map_obj=map_obj)\n",
    "            if r == 0:\n",
    "                score -= 10\n",
    "            else:\n",
    "                print(r)\n",
    "        elif action == 'w':\n",
    "            print('Waiting...')\n",
    "        score -= 10\n",
    "        render_map(map_obj, agent_obj)\n",
    "        print(f'Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WarehouseEnv(\n",
    "    map_sketch=wm.wh_vis_map, \n",
    "    num_turns=None, \n",
    "    max_order_line=25,\n",
    "    frequency=0.05,\n",
    "    simplified_state=True, \n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 615\n",
      "Penalties incurred: 251\n"
     ]
    }
   ],
   "source": [
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "\n",
    "frames = [] # for animation\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    if reward < -10:\n",
    "        penalties += 1\n",
    "    \n",
    "    # Put each rendered frame into dict for animation\n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': state,\n",
    "        'action': action,\n",
    "        'reward': reward,\n",
    "        'order_list': info['order_list']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    epochs += 1\n",
    "    \n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++\n",
      "+.#..#..#..#..#..#.+\n",
      "+.#..#..#..#..#..#.+\n",
      "+.#..#..#..#..#..#.+\n",
      "+.#..#..#..#..#..#.+\n",
      "+..................+\n",
      "+..................+\n",
      "+.#######..#######.+\n",
      "+..................+\n",
      "+..................+\n",
      "+.#######..#######.+\n",
      "+..................+\n",
      "+..................+\n",
      "+.##..##..##..##..#+\n",
      "+.##..##..##..##..#+\n",
      "+.##..##..##..##..#+\n",
      "+.##..##..##..##..#+\n",
      "+..................+\n",
      "+..X...............+\n",
      "+..................+\n",
      "+$$$$$$$$$$$$$$$$$$+\n",
      "Timestep: 457\n",
      "State: [ 18.           3.         -16.62385405 189.32      ]\n",
      "Action: 2\n",
      "Reward: -10\n",
      "Order list: Ноутбук ASUS ZenBook UX530UQ: 1,\n",
      "Ноутбук HP EliteBook 8570p: 1,\n",
      "Ноутбук DELL INSPIRON 5370: 2,\n",
      "Ноутбук ASUS Eee PC 1000HD: 1,\n",
      "Ноутбук Samsung 535U4C: 2,\n",
      "Ноутбук DELL Vostro 3578: 1,\n",
      "Ноутбук Lenovo ThinkPad 13 Ultrabook: 1,\n",
      "Ноутбук HP PAVILION 15-ck000: 1,\n",
      "Ноутбук Lenovo ThinkPad L390: 1,\n",
      "Ноутбук ASUS VivoBook 15 X542UN: 1,\n",
      "Ноутбук DELL 500: 1,\n",
      "Ноутбук Lenovo IdeaPad 720 15: 1,\n",
      "Ноутбук HP ProBook 430 G6: 1,\n",
      "Ноутбук Apple MacBook Air 13 with Retina display Late 2018: 1,\n",
      "Ноутбук HP PAVILION 14-ba100 x360: 1,\n",
      "Ноутбук ASUS ZenBook UX430UQ: 1,\n",
      "Ноутбук ASUS VivoBook Flip 14 TP401CA: 1,\n",
      "Ноутбук Lenovo Legion Y740-17: 1,\n",
      "Ноутбук Google Pixelbook: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-cc0ea54022e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-246-cc0ea54022e3>\u001b[0m in \u001b[0;36mprint_frames\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reward: {frame['reward']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Order list: {frame['order_list']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        print(f\"Order list: {frame['order_list']}\")\n",
    "        sleep(.1)\n",
    "        \n",
    "print_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training q-learning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_state(state, encoder):\n",
    "    state = tuple(state)\n",
    "    if state not in encoder:\n",
    "        encoder[state] = len(encoder)\n",
    "    return encoder[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n",
      "CPU times: user 26min 19s, sys: 1min 34s, total: 27min 54s\n",
      "Wall time: 26min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"Training the agent\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "q_table = np.zeros([18 * 18 * 4, env.action_space.n])\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.2\n",
    "n_epoch = 100000\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "env = WarehouseEnv()\n",
    "encoder = dict()\n",
    "for i in range(1, n_epoch + 1):\n",
    "    state = env.reset()\n",
    "    state = encode_state(state, encoder)\n",
    "    epochs, penalties, reward, = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample() # Explore action space\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Exploit learned values\n",
    "\n",
    "        next_state, reward, done, info = env.step(action) \n",
    "        \n",
    "        old_value = q_table[state, action]\n",
    "        next_state = encode_state(next_state, encoder)\n",
    "        next_max = np.max(q_table[next_state])\n",
    "        \n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state, action] = new_value\n",
    "        \n",
    "        if reward < -10:\n",
    "            penalties += 1\n",
    "\n",
    "        state = next_state\n",
    "        epochs += 1\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episode: {i}\")\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296, 8)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 100 episodes:\n",
      "Average timesteps per episode: 1000.0\n",
      "Average penalties per episode: 999.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
    "\n",
    "total_epochs, total_penalties = 0, 0\n",
    "episodes = 100\n",
    "\n",
    "for _ in range(episodes):\n",
    "    state = env.reset()\n",
    "    state = encode_state(state, encoder)\n",
    "    epochs, penalties, reward = 0, 0, 0\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state])\n",
    "#         print(state, action)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        state = encode_state(state, encoder)\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "    total_penalties += penalties\n",
    "    total_epochs += epochs\n",
    "\n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 1000\n",
      "Penalties incurred: 0\n"
     ]
    }
   ],
   "source": [
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "\n",
    "frames = [] # for animation\n",
    "\n",
    "done = False\n",
    "\n",
    "state = env.reset()\n",
    "state = encode_state(state, encoder)\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state])\n",
    "    state, reward, done, info = env.step(action)\n",
    "    state = encode_state(state, encoder)\n",
    "    if reward < -10:\n",
    "        penalties += 1\n",
    "    \n",
    "    # Put each rendered frame into dict for animation\n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': state,\n",
    "        'action': action,\n",
    "        'reward': reward\n",
    "        }\n",
    "    )\n",
    "\n",
    "    epochs += 1\n",
    "    \n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        sleep(.05)\n",
    "        \n",
    "print_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.q_table import QTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WarehouseEnv(\n",
    "    map_sketch=wm.wh_vis_map, \n",
    "    num_turns=None, \n",
    "    max_order_line=15,\n",
    "    frequency=-1,\n",
    "    simplified_state=False, \n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.imshow(screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, r, d, i = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.imshow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QTable(\n",
    "    environment=env, \n",
    "    verbose=True,\n",
    "    alpha=0.40,\n",
    "    gamma=0.90,\n",
    "    epsilon=0.27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(n_epoch=30)\n",
    "# model.save_model(os.path.join(models_dir, 'qt_02_08_012_50k'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 10 episodes:\n",
      "Average timesteps per episode: 76.7\n",
      "Average penalties per episode: 0.0\n",
      "Average rewards per episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# model.verbose=True\n",
    "_ = model.evaluate_performance(episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 71\n",
      "Penalties incurred: 0\n",
      "Rewards incurred: 0\n"
     ]
    }
   ],
   "source": [
    "model.operate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++\n",
      "+.#..#..#..#..#..#.+\n",
      "+.#..#..#..#..#..#.+\n",
      "+.#..#..#..#..#..#.+\n",
      "+.#..#..#..#..#..#.+\n",
      "+..................+\n",
      "+..................+\n",
      "+.#######..#######.+\n",
      "+..................+\n",
      "+..................+\n",
      "+.#######..#######.+\n",
      "+..................+\n",
      "+..................+\n",
      "+.##..##..##..##..#+\n",
      "+.##..##..##..##..#+\n",
      "+.##..##..##..##..#+\n",
      "+.##..##..##..##..#+\n",
      "+..................+\n",
      "+........X.........+\n",
      "+..................+\n",
      "+$$$$$$$$$$$$$$$$$$+\n",
      "Timestep: 144\n",
      "State: 0\n",
      "Action: 7\n",
      "Reward: -10\n"
     ]
    }
   ],
   "source": [
    "model.show_operation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OrderList class experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import config as co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs.wh_objects import OrderList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(co.PATH_TO_CATALOG, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>purchase</th>\n",
       "      <th>weigth</th>\n",
       "      <th>long</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ноутбук ASUS ZenBook UX430UQ</td>\n",
       "      <td>57674.133515</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.240</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>16.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ноутбук HP ProBook 655 G3</td>\n",
       "      <td>46060.000000</td>\n",
       "      <td>1.966667</td>\n",
       "      <td>2.31</td>\n",
       "      <td>3.780</td>\n",
       "      <td>2.570</td>\n",
       "      <td>2.570</td>\n",
       "      <td>24.966522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ноутбук Lenovo IdeaPad 320 17 Intel</td>\n",
       "      <td>29750.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.180</td>\n",
       "      <td>2.926</td>\n",
       "      <td>2.926</td>\n",
       "      <td>35.786970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ноутбук Acer ASPIRE S5-371</td>\n",
       "      <td>57490.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.270</td>\n",
       "      <td>2.880</td>\n",
       "      <td>2.880</td>\n",
       "      <td>27.122688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ноутбук Apple MacBook Pro 13 with Retina displ...</td>\n",
       "      <td>155900.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.041</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.124</td>\n",
       "      <td>13.719094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name          price  purchase  \\\n",
       "0                       Ноутбук ASUS ZenBook UX430UQ   57674.133515  0.016667   \n",
       "2                          Ноутбук HP ProBook 655 G3   46060.000000  1.966667   \n",
       "3                Ноутбук Lenovo IdeaPad 320 17 Intel   29750.000000  0.016667   \n",
       "4                         Ноутбук Acer ASPIRE S5-371   57490.000000  5.500000   \n",
       "5  Ноутбук Apple MacBook Pro 13 with Retina displ...  155900.000000  1.800000   \n",
       "\n",
       "   weigth   long  width  depth     volume  \n",
       "0    1.25  3.240  2.250  2.250  16.402500  \n",
       "2    2.31  3.780  2.570  2.570  24.966522  \n",
       "3    2.80  4.180  2.926  2.926  35.786970  \n",
       "4    1.30  3.270  2.880  2.880  27.122688  \n",
       "5    1.37  3.041  2.124  2.124  13.719094  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>purchase</th>\n",
       "      <th>weigth</th>\n",
       "      <th>long</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57674.133515</td>\n",
       "      <td>3.385944</td>\n",
       "      <td>1.946275</td>\n",
       "      <td>3.560887</td>\n",
       "      <td>2.462067</td>\n",
       "      <td>2.462067</td>\n",
       "      <td>22.237322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39553.855916</td>\n",
       "      <td>4.082269</td>\n",
       "      <td>0.600479</td>\n",
       "      <td>0.375054</td>\n",
       "      <td>0.280453</td>\n",
       "      <td>0.280453</td>\n",
       "      <td>6.868680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>8.640162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32602.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>2.265000</td>\n",
       "      <td>2.265000</td>\n",
       "      <td>16.745054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54525.000000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.946275</td>\n",
       "      <td>3.614000</td>\n",
       "      <td>2.465000</td>\n",
       "      <td>2.465000</td>\n",
       "      <td>22.395591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68836.000000</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.814500</td>\n",
       "      <td>2.602250</td>\n",
       "      <td>2.602250</td>\n",
       "      <td>25.817859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>274870.000000</td>\n",
       "      <td>16.316667</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>4.323000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>46.734976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price    purchase      weigth        long       width  \\\n",
       "count     415.000000  415.000000  415.000000  411.000000  410.000000   \n",
       "mean    57674.133515    3.385944    1.946275    3.560887    2.462067   \n",
       "std     39553.855916    4.082269    0.600479    0.375054    0.280453   \n",
       "min       100.000000    0.016667    0.850000    2.580000    1.830000   \n",
       "25%     32602.500000    0.533333    1.500000    3.240000    2.265000   \n",
       "50%     54525.000000    1.583333    1.946275    3.614000    2.465000   \n",
       "75%     68836.000000    4.975000    2.200000    3.814500    2.602250   \n",
       "max    274870.000000   16.316667    4.700000    4.323000    3.800000   \n",
       "\n",
       "            depth      volume  \n",
       "count  410.000000  409.000000  \n",
       "mean     2.462067   22.237322  \n",
       "std      0.280453    6.868680  \n",
       "min      1.830000    8.640162  \n",
       "25%      2.265000   16.745054  \n",
       "50%      2.465000   22.395591  \n",
       "75%      2.602250   25.817859  \n",
       "max      3.800000   46.734976  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 415 entries, 0 to 424\n",
      "Data columns (total 8 columns):\n",
      "name        415 non-null object\n",
      "price       415 non-null float64\n",
      "purchase    415 non-null float64\n",
      "weigth      415 non-null float64\n",
      "long        411 non-null float64\n",
      "width       410 non-null float64\n",
      "depth       410 non-null float64\n",
      "volume      409 non-null float64\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 29.2+ KB\n"
     ]
    }
   ],
   "source": [
    "catalog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405.1666666666667\n"
     ]
    }
   ],
   "source": [
    "print(catalog.purchase.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol = OrderList(path_to_catalog=co.PATH_TO_CATALOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ноутбук ASUS Vivobook 17 X705MA: 1,\n",
      "Ноутбук MSI GF75 Thin 8RC: 1,\n",
      "Ноутбук ASUS TUF Gaming FX705GM: 1,\n",
      "Ноутбук HP 17-bs000: 1,\n",
      "Ноутбук Lenovo THINKPAD T530: 1,\n",
      "Ноутбук MSI GE75 8SF Raider: 1\n"
     ]
    }
   ],
   "source": [
    "ol()\n",
    "print(ol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([int(prod.n_purchase) for prod in ol.list_of_products])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ol['Ноутбук MSI GE75 8SF Raider']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from collections import Counter, deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.core import Processor\n",
    "from rl.policy import BoltzmannQPolicy, LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, n_actions):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_actions, activation='softmax'))\n",
    "    model.compile(Adam(lr=1e-3), 'mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(23,20,1), n_actions=env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProcessor(Processor):\n",
    "    '''\n",
    "    acts as a coupling mechanism between the agent and the environment\n",
    "    '''\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        '''\n",
    "        Given a state batch, I want to remove the second dimension, because it's\n",
    "        useless and prevents me from feeding the tensor into my CNN\n",
    "        '''\n",
    "        return np.squeeze(batch, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 21, 18, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 19, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 609,671\n",
      "Trainable params: 609,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "# policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05, nb_steps=50000)\n",
    "dqn = DQNAgent(model=model, nb_actions=env.action_space.n, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy, processor=pr)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = CustomProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
      "/anaconda3/envs/reinforcement_learning/lib/python3.7/site-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 490.678 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1355b9f60>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=50000, visualize=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
